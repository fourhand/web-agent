from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import AzureOpenAI
from starlette.websockets import WebSocketDisconnect
import os, json, re, logging, base64, random
from datetime import datetime
import asyncio
from urllib.parse import quote
from typing import Dict, List, Any, Optional, TypedDict

# LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import AzureChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.schema import Document
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()
logger = logging.getLogger("uvicorn.error")
logging.basicConfig(level=logging.INFO)

# ============================
# State Management
# ============================
class AgentState(TypedDict):
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    goal: str
    current_step: int
    total_steps: int
    plan: List[Dict[str, Any]]
    dom_elements: List[Dict[str, Any]]
    dom_vectorstore: Optional[Chroma]
    last_action: Optional[Dict[str, Any]]
    action_history: List[Dict[str, Any]]
    messages: List[Any]
    current_page_url: str
    status: str  # 'planning', 'executing', 'evaluating', 'completed', 'error'
    error_message: Optional[str]

# ============================
# LLM Setup
# ============================
def create_llm():
    """Azure OpenAI LLM ìƒì„±"""
    return AzureChatOpenAI(
        azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4.1-mini"),
        openai_api_version="2024-02-15-preview",
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        temperature=0.1,
        max_tokens=1000
    )

def create_vision_llm():
    """Azure OpenAI Vision LLM ìƒì„±"""
    return AzureChatOpenAI(
        azure_deployment=os.getenv("AZURE_OPENAI_VISION_DEPLOYMENT_NAME", "gpt-4.1-mini"),
        openai_api_version="2024-02-15-preview",
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        temperature=0.1,
        max_tokens=1000
    )

# ============================
# DOM Vector Store Management
# ============================
def create_dom_vectorstore(dom_elements: List[Dict[str, Any]]) -> Chroma:
    """DOM ìš”ì†Œë“¤ì„ VectorStoreë¡œ ë³€í™˜"""
    try:
        # DOM ìš”ì†Œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        documents = []
        for i, element in enumerate(dom_elements):
            text = f"Element {i}: {element.get('tag', '')} - {element.get('text', '')} - {element.get('class', '')} - {element.get('id', '')}"
            metadata = {
                "index": i,
                "tag": element.get("tag", ""),
                "text": element.get("text", ""),
                "class": element.get("class", ""),
                "id": element.get("id", ""),
                "selector": element.get("selector", ""),
                "is_clickable": element.get("is_clickable", False),
                "is_input": element.get("is_input", False)
            }
            documents.append(Document(page_content=text, metadata=metadata))
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        split_docs = text_splitter.split_documents(documents)
        
        # VectorStore ìƒì„±
        embeddings = OpenAIEmbeddings(
            azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME", "text-embedding-ada-002"),
            openai_api_version="2024-02-15-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY")
        )
        
        vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=embeddings,
            collection_name=f"dom_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        
        logger.info(f"âœ… DOM VectorStore ìƒì„± ì™„ë£Œ: {len(split_docs)}ê°œ ì²­í¬")
        return vectorstore
        
    except Exception as e:
        logger.error(f"âŒ DOM VectorStore ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def search_dom_elements(vectorstore: Chroma, query: str, k: int = 5) -> List[Dict[str, Any]]:
    """DOM ìš”ì†Œ ê²€ìƒ‰"""
    try:
        results = vectorstore.similarity_search(query, k=k)
        elements = []
        for doc in results:
            elements.append(doc.metadata)
        return elements
    except Exception as e:
        logger.error(f"âŒ DOM ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

# ============================
# LangGraph Nodes
# ============================
def analyze_goal(state: AgentState) -> AgentState:
    """ëª©í‘œ ë¶„ì„ ë° ì´ˆê¸° ê³„íš ìˆ˜ë¦½"""
    try:
        llm = create_llm()
        
        prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì›¹ ì„œí•‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ëª©í‘œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¨ê³„ë³„ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ëª©í‘œ: {goal}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”:
[
  {{
    "step": 1,
    "action": "goto|click|fill|wait|extract",
    "description": "ì´ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•  ì‘ì—… ì„¤ëª…",
    "expected_outcome": "ì˜ˆìƒ ê²°ê³¼",
    "requirements": ["í•„ìš”í•œ ìš”ì†Œë“¤"]
  }}
]

ê³„íšì€ 3-8ë‹¨ê³„ë¡œ êµ¬ì„±í•˜ê³ , ê° ë‹¨ê³„ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
""")
        
        chain = prompt | llm | JsonOutputParser()
        plan = chain.invoke({"goal": state["goal"]})
        
        state["plan"] = plan
        state["total_steps"] = len(plan)
        state["status"] = "planning"
        state["current_step"] = 0
        
        logger.info(f"âœ… ëª©í‘œ ë¶„ì„ ì™„ë£Œ: {len(plan)}ë‹¨ê³„ ê³„íš ìˆ˜ë¦½")
        return state
        
    except Exception as e:
        logger.error(f"âŒ ëª©í‘œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        state["status"] = "error"
        state["error_message"] = f"ëª©í‘œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        return state

def create_dom_vectorstore_node(state: AgentState) -> AgentState:
    """DOM VectorStore ìƒì„±"""
    try:
        if not state["dom_elements"]:
            logger.warning("âš ï¸ DOM ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤")
            return state
        
        vectorstore = create_dom_vectorstore(state["dom_elements"])
        state["dom_vectorstore"] = vectorstore
        state["status"] = "executing"
        
        logger.info(f"âœ… DOM VectorStore ìƒì„± ì™„ë£Œ: {len(state['dom_elements'])}ê°œ ìš”ì†Œ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ DOM VectorStore ìƒì„± ì‹¤íŒ¨: {e}")
        state["status"] = "error"
        state["error_message"] = f"DOM VectorStore ìƒì„± ì‹¤íŒ¨: {str(e)}"
        return state

def execute_action(state: AgentState) -> AgentState:
    """í˜„ì¬ ë‹¨ê³„ ì•¡ì…˜ ì‹¤í–‰"""
    try:
        if state["current_step"] >= len(state["plan"]):
            state["status"] = "completed"
            return state
        
        current_plan = state["plan"][state["current_step"]]
        action_type = current_plan["action"]
        
        # DOM ê²€ìƒ‰ì„ í†µí•œ ìš”ì†Œ ì°¾ê¸°
        if state["dom_vectorstore"] and action_type in ["click", "fill"]:
            query = current_plan["description"]
            elements = search_dom_elements(state["dom_vectorstore"], query)
            
            if elements:
                # ê°€ì¥ ì í•©í•œ ìš”ì†Œ ì„ íƒ
                best_element = elements[0]
                action = {
                    "action": action_type,
                    "selector": best_element.get("selector", ""),
                    "text": best_element.get("text", ""),
                    "description": current_plan["description"],
                    "step": state["current_step"] + 1
                }
                
                state["last_action"] = action
                state["action_history"].append(action)
                state["current_step"] += 1
                
                logger.info(f"âœ… ì•¡ì…˜ ì‹¤í–‰: {action_type} - {current_plan['description']}")
            else:
                logger.warning(f"âš ï¸ ì í•©í•œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {query}")
                state["status"] = "error"
                state["error_message"] = f"ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {query}"
        else:
            # goto, wait ë“±ì˜ ì•¡ì…˜
            action = {
                "action": action_type,
                "description": current_plan["description"],
                "step": state["current_step"] + 1
            }
            
            state["last_action"] = action
            state["action_history"].append(action)
            state["current_step"] += 1
        
        return state
        
    except Exception as e:
        logger.error(f"âŒ ì•¡ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        state["status"] = "error"
        state["error_message"] = f"ì•¡ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        return state

def evaluate_progress(state: AgentState) -> AgentState:
    """ì§„í–‰ ìƒí™© í‰ê°€"""
    try:
        llm = create_llm()
        
        progress_percentage = (state["current_step"] / state["total_steps"]) * 100 if state["total_steps"] > 0 else 0
        
        prompt = ChatPromptTemplate.from_template("""
í˜„ì¬ ì›¹ ìë™í™” ì§„í–‰ ìƒí™©ì„ í‰ê°€í•˜ì„¸ìš”.

ëª©í‘œ: {goal}
í˜„ì¬ ë‹¨ê³„: {current_step}/{total_steps}
ì§„í–‰ë¥ : {progress_percentage:.1f}%
ë§ˆì§€ë§‰ ì•¡ì…˜: {last_action}

í‰ê°€ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "status": "continue|completed|error|replan",
    "reason": "í‰ê°€ ì´ìœ ",
    "next_action": "ë‹¤ìŒì— í•  ì¼",
    "confidence": 0.0-1.0
}}
""")
        
        chain = prompt | llm | JsonOutputParser()
        evaluation = chain.invoke({
            "goal": state["goal"],
            "current_step": state["current_step"],
            "total_steps": state["total_steps"],
            "progress_percentage": progress_percentage,
            "last_action": json.dumps(state["last_action"], ensure_ascii=False) if state["last_action"] else "None"
        })
        
        if evaluation["status"] == "completed":
            state["status"] = "completed"
        elif evaluation["status"] == "replan":
            state["status"] = "planning"
            state["plan"] = []  # ì¬ê³„íšì„ ìœ„í•´ ì´ˆê¸°í™”
        
        logger.info(f"âœ… ì§„í–‰ ìƒí™© í‰ê°€: {evaluation['status']} - {evaluation['reason']}")
        return state
        
    except Exception as e:
        logger.error(f"âŒ ì§„í–‰ ìƒí™© í‰ê°€ ì‹¤íŒ¨: {e}")
        state["status"] = "error"
        state["error_message"] = f"ì§„í–‰ ìƒí™© í‰ê°€ ì‹¤íŒ¨: {str(e)}"
        return state

# ============================
# LangGraph Workflow
# ============================
def create_workflow() -> StateGraph:
    """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    
    # ìƒíƒœ ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze_goal", analyze_goal)
    workflow.add_node("create_dom_vectorstore", create_dom_vectorstore_node)
    workflow.add_node("execute_action", execute_action)
    workflow.add_node("evaluate_progress", evaluate_progress)
    
    # ì—£ì§€ ì •ì˜
    workflow.set_entry_point("analyze_goal")
    
    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…
    def route_after_analysis(state: AgentState) -> str:
        # DOM ìš”ì†Œê°€ ì—†ìœ¼ë©´ ëŒ€ê¸°
        if not state.get("dom_elements") or len(state["dom_elements"]) == 0:
            return END
        if state["status"] == "error":
            return END
        elif state["dom_elements"]:
            return "create_dom_vectorstore"
        else:
            return "execute_action"
    
    def route_after_vectorstore(state: AgentState) -> str:
        if state["status"] == "error":
            return END
        return "execute_action"
    
    def route_after_action(state: AgentState) -> str:
        if state["status"] == "error":
            return END
        elif state["status"] == "completed":
            return END
        elif state["current_step"] >= state["total_steps"]:
            return "evaluate_progress"
        else:
            return "execute_action"
    
    def route_after_evaluation(state: AgentState) -> str:
        if state["status"] == "error":
            return END
        elif state["status"] == "completed":
            return END
        elif state["status"] == "planning":
            return "analyze_goal"
        else:
            return "execute_action"
    
    # ì—£ì§€ ì—°ê²°
    workflow.add_conditional_edges("analyze_goal", route_after_analysis)
    workflow.add_conditional_edges("create_dom_vectorstore", route_after_vectorstore)
    workflow.add_conditional_edges("execute_action", route_after_action)
    workflow.add_conditional_edges("evaluate_progress", route_after_evaluation)
    
    return workflow

# ============================
# FastAPI App
# ============================
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì›Œí¬í”Œë¡œìš° ìƒì„±
workflow = create_workflow()
memory = MemorySaver()
app_graph = workflow.compile()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    logger.info("ğŸ”Œ LangGraph WebSocket ì—°ê²° ìˆ˜ë½ë¨")
    
    try:
        while True:
            raw = await websocket.receive_text()
            try:
                payload = json.loads(raw)
                logger.info(f"ğŸ“¨ ë©”ì‹œì§€ ìˆ˜ì‹ : {payload.get('type')}")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
            
            if payload.get("type") == "init":
                # ìƒˆë¡œìš´ ì‘ì—… ì‹œì‘
                user_goal = payload["message"]
                logger.info(f"ğŸ†• ìƒˆ ëª©í‘œ: {user_goal}")
                
                # ì´ˆê¸° ìƒíƒœ ì„¤ì •
                initial_state = AgentState(
                    goal=user_goal,
                    current_step=0,
                    total_steps=0,
                    plan=[],
                    dom_elements=[],
                    dom_vectorstore=None,
                    last_action=None,
                    action_history=[],
                    messages=[],
                    current_page_url="",
                    status="planning",
                    error_message=None
                )
                
                # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                try:
                    result = await app_graph.ainvoke(initial_state, config={"configurable": {"thread_id": "default"}})
                    
                    # ê²°ê³¼ ì „ì†¡
                    await websocket.send_text(json.dumps({
                        "type": "workflow_result",
                        "status": result["status"],
                        "plan": result["plan"],
                        "action_history": result["action_history"],
                        "current_step": result["current_step"],
                        "total_steps": result["total_steps"],
                        "error_message": result.get("error_message")
                    }, ensure_ascii=False))
                    
                except Exception as e:
                    logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "detail": f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
                    }))
            
            elif payload.get("type") == "dom_with_image":
                # DOM ì •ë³´ ì—…ë°ì´íŠ¸
                dom_elements = payload.get("dom", [])
                logger.info(f"ğŸ“Š DOM ì—…ë°ì´íŠ¸: {len(dom_elements)}ê°œ ìš”ì†Œ")
                
                # í˜„ì¬ ìƒíƒœì— DOM ì¶”ê°€
                # ì‹¤ì œë¡œëŠ” ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìƒíƒœë¥¼ ë³µì›í•´ì•¼ í•¨
                await websocket.send_text(json.dumps({
                    "type": "dom_updated",
                    "message": f"DOM {len(dom_elements)}ê°œ ìš”ì†Œ ì—…ë°ì´íŠ¸ë¨"
                }))
            
            elif payload.get("type") == "execute_action":
                # íŠ¹ì • ì•¡ì…˜ ì‹¤í–‰
                action = payload.get("action")
                if action:
                    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìƒíƒœ ë³µì› í›„ ì•¡ì…˜ ì‹¤í–‰
                    await websocket.send_text(json.dumps({
                        "type": "action_executed",
                        "action": action
                    }))
    
    except WebSocketDisconnect:
        logger.info("ğŸ”Œ WebSocket ì—°ê²° í•´ì œë¨")
    except Exception as e:
        logger.error(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
        try:
            await websocket.send_text(json.dumps({
                "type": "error",
                "detail": str(e)
            }))
        except:
            pass

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
